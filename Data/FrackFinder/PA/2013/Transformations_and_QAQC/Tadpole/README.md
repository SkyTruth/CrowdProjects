Tadpole Transformations
=======================

Author: Kevin Wurster - <kevin@skytruth.org>
[GitHub Repository](https://github.com/SkyTruth/CrowdProjects)
Software: QGIS 2.2, GDAL 1.11.0, Python 2.7.7, PyCharm 3.4.1, Mac 10.9.3

An explanation of how the pad classifications generated by Tadpole were processed and turned
into MoorFrog input.



### General Description ###
1. Download tasks
2. Transform data
3. Sample/QAQC



1. Download Data
----------------

The data was split between two different applications, `public` and `internal`, each containing
half of the Tadpole input tasks.  Tasks were placed in:

>       ./tasks/public/*.json
>       ./tasks/internal/*.json



2. Transform Data
-----------------

Since all tasks were only completed in one location, the data can be combined, however we want
to be able to know where each task came from, so first we have to add a `ST_source` field.

>       CrowdProjects/bin/editJSON.py -a ST_source=public tasks/public/task.json tasks/added_fields/public/added-fields-task.json
>       CrowdProjects/bin/editJSON.py -a ST_source=public tasks/public/task_run.json tasks/added_fields/public/added-fields-task_run.json
>       CrowdProjects/bin/editJSON.py -a ST_source=internal tasks/internal/task.json tasks/added_fields/internal/added-fields-task.json
>       CrowdProjects/bin/editJSON.py -a ST_source=internal tasks/internal/task_run.json tasks/added_fields/internal/added-fields-task_run.json

After adding the source field, the data was combined into a single task.json and task_run.json:

>       CrowdProjects/bin/mergeFiles.py tasks/added_fields/public/added-fields-task.json tasks/added_fields/internal/added-fields-task.json tasks/combined-task.json  
>       CrowdProjects/bin/mergeFiles.py tasks/added_fields/public/added-fields-task_run.json tasks/added_fields/internal/added-fields-task_run.json tasks/combined-task_run.json

These combined files can now be converted into a single shapefile:

>       ./bin/tadpole-task2shp.py tasks/combined-task.json tasks/combined-task_run.json transform/stats/tadpole-stats.shp --class=%ST_source

Field Definitions:

>       id  ->  task.json['id']
>       site_id  ->  task.json['info']['siteID']
>       wms_url  ->  URL for appropriate imagery
>       county  ->  County name
>       state  ->  State abbreviation
>       year  ->  Year original permits were created
>       location  ->  Generated primary key based on lat + long + year
>       n_unk_res  ->  Number of task runs marked as 'unknown' - task_run.json['info']['selection']  
>       n_nop_res  ->  Number of task runs marked as 'nopad' - task_run.json['info']['selection']
>       n_pad_res  ->  Number of task runs marked as 'pad' - task_run.json['info']['selection']
>       n_tot_res  ->  Total number of times a task was completed in task_run.json
>       crowd_sel  ->  The most picked task_run.json['info']['selection'] - some are split with '|'
>       qaqc  ->  String field for use when performing QAQC
>       p_crd_a  ->  Percentage of responses that agreed with the crowd_sel field
>       p_s_crd_a  ->  If two selections were favored equally, the p_crd_a for each separated by '|'
>       class  ->  User defined classification - in this case it specifies public vs. internal



3. Sample/QAQC
--------------

A random sample size of 5% for each application was selected after exploring the data.  A total 
of `4241` tasks were were completed, half in the public application and half in an internal
application, yielding `106` samples per application.  Each task in the public application was
completed 10 times and each task in the internal application was completed 3 times.  PyBossa
calls this the redundancy.

After exploring the `./transform/stats/moorfrog-stats.shp` file, a sample size of 5% was selected
based on the fact that `93%` of tasks had an agreement level greater than or equal to 70%, which
justifies sampling the entire population rather than a subset.

The random sampling tool in `QGIS` was used, however a bug requires a small pre-processing step.
For some reason the random sampling tool totally ignores any datasource filters, so the data must
first be queried and saved to a new file before performing the selection.  The queries and output
files are as follows:

>       "class" = 'public'   -> ./sampling/queries/moorfrog-public.shp
>       "class" = 'internal' -> sampling/queries/moorfrog-internal.shp

The subsequent files were loaded into `QGIS` and a sample of `5%` for each application was selected
with the random sampling tool.  The selections were saved in the following locations:

>       ./sampling/public/moorfrog-public-5percent-sample.shp
>       ./sampling/internal/moorfrog-internal-5percent-sample.shp

### Sampling Results ###

RESULTS